{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "while not os.path.isfile(\"README.md\"):\n",
    "    %cd ..\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import compute_sample_weight\n",
    "import shap\n",
    "import lightgbm as lgb\n",
    "from lib.preprocess import get_data, Preprocess\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "BASE_PATH = os.path.abspath(\"\")\n",
    "FILE_NAME = \"lgbm_main\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_f1score(preds:np.ndarray,eval_data: lgb.Dataset):\n",
    "    y_true = eval_data.get_label()\n",
    "    weight = eval_data.get_weight()\n",
    "    preds = preds.reshape(len(np.unique(y_true)), -1)\n",
    "    preds = preds.argmax(axis = 0)\n",
    "    f1 = f1_score(y_true,preds,average='macro',sample_weight=weight)\n",
    "    return 'f1',f1,True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'metric': None,\n",
    "    'num_class': 2,\n",
    "    'seed': 42,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1761]\tval's multi_logloss: 0.367162\tval's f1: 0.636748\n",
      "[1762]\tval's multi_logloss: 0.367163\tval's f1: 0.636748\n",
      "[1763]\tval's multi_logloss: 0.367234\tval's f1: 0.636748\n",
      "[1764]\tval's multi_logloss: 0.367333\tval's f1: 0.636748\n",
      "[1765]\tval's multi_logloss: 0.367472\tval's f1: 0.636748\n",
      "[1766]\tval's multi_logloss: 0.3675\tval's f1: 0.636748\n",
      "[1767]\tval's multi_logloss: 0.367569\tval's f1: 0.636913\n",
      "[1768]\tval's multi_logloss: 0.367646\tval's f1: 0.63762\n",
      "[1769]\tval's multi_logloss: 0.367757\tval's f1: 0.63762\n",
      "[1770]\tval's multi_logloss: 0.36787\tval's f1: 0.63762\n",
      "[1771]\tval's multi_logloss: 0.367962\tval's f1: 0.636913\n",
      "[1772]\tval's multi_logloss: 0.368052\tval's f1: 0.636913\n",
      "[1773]\tval's multi_logloss: 0.368189\tval's f1: 0.636913\n",
      "[1774]\tval's multi_logloss: 0.368262\tval's f1: 0.636913\n",
      "[1775]\tval's multi_logloss: 0.368345\tval's f1: 0.638325\n",
      "[1776]\tval's multi_logloss: 0.368414\tval's f1: 0.63762\n",
      "[1777]\tval's multi_logloss: 0.368472\tval's f1: 0.63762\n",
      "[1778]\tval's multi_logloss: 0.368454\tval's f1: 0.637786\n",
      "[1779]\tval's multi_logloss: 0.368523\tval's f1: 0.637786\n",
      "[1780]\tval's multi_logloss: 0.368611\tval's f1: 0.63762\n",
      "[1781]\tval's multi_logloss: 0.368713\tval's f1: 0.63762\n",
      "[1782]\tval's multi_logloss: 0.368823\tval's f1: 0.63762\n",
      "[1783]\tval's multi_logloss: 0.368869\tval's f1: 0.63762\n",
      "[1784]\tval's multi_logloss: 0.36896\tval's f1: 0.63762\n",
      "[1785]\tval's multi_logloss: 0.368965\tval's f1: 0.637454\n",
      "[1786]\tval's multi_logloss: 0.369042\tval's f1: 0.637454\n",
      "[1787]\tval's multi_logloss: 0.369095\tval's f1: 0.637454\n",
      "[1788]\tval's multi_logloss: 0.369228\tval's f1: 0.637454\n",
      "[1789]\tval's multi_logloss: 0.369285\tval's f1: 0.637454\n",
      "[1790]\tval's multi_logloss: 0.369349\tval's f1: 0.637454\n",
      "[1791]\tval's multi_logloss: 0.369466\tval's f1: 0.637454\n",
      "[1792]\tval's multi_logloss: 0.36949\tval's f1: 0.637454\n",
      "[1793]\tval's multi_logloss: 0.369581\tval's f1: 0.637288\n",
      "[1794]\tval's multi_logloss: 0.369727\tval's f1: 0.637288\n",
      "[1795]\tval's multi_logloss: 0.369832\tval's f1: 0.637288\n",
      "[1796]\tval's multi_logloss: 0.369931\tval's f1: 0.636748\n",
      "[1797]\tval's multi_logloss: 0.369984\tval's f1: 0.636748\n",
      "[1798]\tval's multi_logloss: 0.369979\tval's f1: 0.636748\n",
      "[1799]\tval's multi_logloss: 0.370143\tval's f1: 0.636041\n",
      "[1800]\tval's multi_logloss: 0.370156\tval's f1: 0.636041\n",
      "[1801]\tval's multi_logloss: 0.370238\tval's f1: 0.636206\n",
      "[1802]\tval's multi_logloss: 0.370414\tval's f1: 0.636913\n",
      "[1803]\tval's multi_logloss: 0.370492\tval's f1: 0.636206\n",
      "[1804]\tval's multi_logloss: 0.370516\tval's f1: 0.636206\n",
      "[1805]\tval's multi_logloss: 0.370554\tval's f1: 0.636206\n",
      "[1806]\tval's multi_logloss: 0.370649\tval's f1: 0.636041\n",
      "[1807]\tval's multi_logloss: 0.370649\tval's f1: 0.635876\n",
      "[1808]\tval's multi_logloss: 0.370724\tval's f1: 0.635876\n",
      "[1809]\tval's multi_logloss: 0.370756\tval's f1: 0.635876\n",
      "[1810]\tval's multi_logloss: 0.370771\tval's f1: 0.635876\n",
      "[1811]\tval's multi_logloss: 0.370825\tval's f1: 0.635876\n",
      "[1812]\tval's multi_logloss: 0.370956\tval's f1: 0.635876\n",
      "[1813]\tval's multi_logloss: 0.371102\tval's f1: 0.635168\n",
      "[1814]\tval's multi_logloss: 0.371136\tval's f1: 0.635168\n",
      "[1815]\tval's multi_logloss: 0.37121\tval's f1: 0.635168\n",
      "[1816]\tval's multi_logloss: 0.371214\tval's f1: 0.635168\n",
      "[1817]\tval's multi_logloss: 0.371371\tval's f1: 0.636417\n",
      "[1818]\tval's multi_logloss: 0.37142\tval's f1: 0.636417\n",
      "[1819]\tval's multi_logloss: 0.371523\tval's f1: 0.636582\n",
      "[1820]\tval's multi_logloss: 0.371709\tval's f1: 0.636417\n",
      "[1821]\tval's multi_logloss: 0.37168\tval's f1: 0.635876\n",
      "[1822]\tval's multi_logloss: 0.371866\tval's f1: 0.635876\n",
      "[1823]\tval's multi_logloss: 0.371947\tval's f1: 0.635876\n",
      "[1824]\tval's multi_logloss: 0.372114\tval's f1: 0.636582\n",
      "[1825]\tval's multi_logloss: 0.372226\tval's f1: 0.636582\n",
      "[1826]\tval's multi_logloss: 0.372258\tval's f1: 0.636582\n",
      "[1827]\tval's multi_logloss: 0.372452\tval's f1: 0.636582\n",
      "[1828]\tval's multi_logloss: 0.372519\tval's f1: 0.636582\n",
      "[1829]\tval's multi_logloss: 0.372588\tval's f1: 0.636417\n",
      "[1830]\tval's multi_logloss: 0.372697\tval's f1: 0.636417\n",
      "[1831]\tval's multi_logloss: 0.372808\tval's f1: 0.636582\n",
      "[1832]\tval's multi_logloss: 0.372886\tval's f1: 0.636582\n",
      "[1833]\tval's multi_logloss: 0.373035\tval's f1: 0.636582\n",
      "[1834]\tval's multi_logloss: 0.373108\tval's f1: 0.636582\n",
      "[1835]\tval's multi_logloss: 0.373156\tval's f1: 0.636748\n",
      "[1836]\tval's multi_logloss: 0.373155\tval's f1: 0.636913\n",
      "[1837]\tval's multi_logloss: 0.373211\tval's f1: 0.636748\n",
      "[1838]\tval's multi_logloss: 0.373282\tval's f1: 0.636748\n",
      "[1839]\tval's multi_logloss: 0.373351\tval's f1: 0.636041\n",
      "[1840]\tval's multi_logloss: 0.373415\tval's f1: 0.636041\n",
      "[1841]\tval's multi_logloss: 0.373533\tval's f1: 0.636041\n",
      "[1842]\tval's multi_logloss: 0.37359\tval's f1: 0.636041\n",
      "[1843]\tval's multi_logloss: 0.373696\tval's f1: 0.636041\n",
      "[1844]\tval's multi_logloss: 0.373802\tval's f1: 0.636041\n",
      "[1845]\tval's multi_logloss: 0.373925\tval's f1: 0.636041\n",
      "[1846]\tval's multi_logloss: 0.373944\tval's f1: 0.636041\n",
      "[1847]\tval's multi_logloss: 0.37407\tval's f1: 0.636041\n",
      "[1848]\tval's multi_logloss: 0.374174\tval's f1: 0.636041\n",
      "[1849]\tval's multi_logloss: 0.374192\tval's f1: 0.634787\n",
      "[1850]\tval's multi_logloss: 0.374227\tval's f1: 0.635662\n",
      "[1851]\tval's multi_logloss: 0.374323\tval's f1: 0.635662\n",
      "[1852]\tval's multi_logloss: 0.374411\tval's f1: 0.636371\n",
      "[1853]\tval's multi_logloss: 0.374526\tval's f1: 0.636371\n",
      "[1854]\tval's multi_logloss: 0.374607\tval's f1: 0.635497\n",
      "[1855]\tval's multi_logloss: 0.374627\tval's f1: 0.635497\n",
      "[1856]\tval's multi_logloss: 0.374635\tval's f1: 0.635497\n",
      "[1857]\tval's multi_logloss: 0.374676\tval's f1: 0.635497\n",
      "[1858]\tval's multi_logloss: 0.374793\tval's f1: 0.635497\n",
      "[1859]\tval's multi_logloss: 0.374899\tval's f1: 0.635497\n",
      "[1860]\tval's multi_logloss: 0.374948\tval's f1: 0.635497\n",
      "[1861]\tval's multi_logloss: 0.375023\tval's f1: 0.635497\n",
      "[1862]\tval's multi_logloss: 0.375096\tval's f1: 0.635497\n",
      "[1863]\tval's multi_logloss: 0.375183\tval's f1: 0.635497\n",
      "[1864]\tval's multi_logloss: 0.37528\tval's f1: 0.635497\n",
      "[1865]\tval's multi_logloss: 0.375388\tval's f1: 0.635497\n",
      "[1866]\tval's multi_logloss: 0.37543\tval's f1: 0.635497\n",
      "[1867]\tval's multi_logloss: 0.375483\tval's f1: 0.634787\n",
      "[1868]\tval's multi_logloss: 0.375501\tval's f1: 0.634787\n",
      "[1869]\tval's multi_logloss: 0.37565\tval's f1: 0.634787\n",
      "[1870]\tval's multi_logloss: 0.375629\tval's f1: 0.634787\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35390/538467234.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_trn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_trn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# ,weight=compute_sample_weight(class_weight='balanced',y=y_trn))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     model = lgb.train(\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    290\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3019\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__set_objective_to_none\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3020\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot update due to null objective function.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3021\u001b[0;31m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0m\u001b[1;32m   3022\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 ctypes.byref(is_finished)))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_score = 0 \n",
    "for fold, (trn_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "    # split\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    X_trn = X_train.iloc[trn_idx].copy()\n",
    "    y_trn = y_train.iloc[trn_idx].copy()\n",
    "    X_val = X_train.iloc[val_idx].copy()\n",
    "    y_val = y_train.iloc[val_idx].copy()\n",
    "\n",
    "    # preprocess\n",
    "    ppr = Preprocess()\n",
    "    X_trn = ppr.fit_transform(X_trn, y_trn)\n",
    "    X_val = ppr.transform(X_val)\n",
    "\n",
    "    # train\n",
    "    train_set = lgb.Dataset(X_trn, y_trn)# ,weight=compute_sample_weight(class_weight='balanced',y=y_trn))\n",
    "    val_set = lgb.Dataset(X_val, y_val, reference=train_set)\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set,\n",
    "        num_boost_round=10000,\n",
    "        valid_sets=[val_set],\n",
    "        valid_names=[\"val\"],\n",
    "        feval=mean_f1score,\n",
    "        callbacks=[\n",
    "            # lgb.early_stopping(500,)\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # inference\n",
    "    preds = model.predict(X_val)\n",
    "    preds = preds.reshape(len(np.unique(y_val)), -1)\n",
    "    preds = preds.argmax(axis = 0)\n",
    "    print(\"0, 1: \",sum(preds==0), sum(preds==1))\n",
    "    score = f1_score(y_val, preds, average='macro')\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_xval = X_val\n",
    "        best_yval = y_val\n",
    "        best_ppr = ppr\n",
    "        best_model = model\n",
    "    print(f\"Score: {score}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration\n",
    "print(f\"Best CV score before calibration: {best_score}\")\n",
    "zero_ratio = sum(best_yval==0) / len(best_yval)\n",
    "n_zero = int(zero_ratio * len(best_yval))\n",
    "y_prob = best_model.predict(best_xval)\n",
    "y_prob = y_prob.reshape(len(np.unique(best_yval)), -1)\n",
    "y_prob = pd.DataFrame(y_prob.T, columns=[\"0\", \"1\"], index=best_xval.index)\n",
    "y_pred = pd.DataFrame([1]*len(best_xval), columns=[\"pred\"], index=best_xval.index)\n",
    "y_pred.loc[y_prob.sort_values(\"0\").index[:n_zero]] = 0\n",
    "score = f1_score(best_yval, y_pred, average='macro')\n",
    "print(f\"Best CV score after calibration: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission\n",
    "n_zero = int(zero_ratio * len(X_test))\n",
    "X_test = best_ppr.transform(X_test)\n",
    "probs = best_model.predict(X_test)\n",
    "probs = probs.reshape(len(np.unique(y_train)), -1)\n",
    "probs = pd.DataFrame(probs.T, columns=[\"0\", \"1\"], index=X_test.index)\n",
    "preds = pd.DataFrame([1]*len(X_test), columns=[\"pred\"], index=X_test.index)\n",
    "preds.loc[probs.sort_values(\"0\").index[:n_zero]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = f\"results/{FILE_NAME}\"\n",
    "if os.path.exists(result_dir):\n",
    "    idx = 1\n",
    "    result_dir += f\"_v{idx}\"\n",
    "    while os.path.exists(result_dir):\n",
    "        idx += 1\n",
    "        result_dir = result_dir.split('_v')[0]\n",
    "        result_dir += f\"_v{idx}\"\n",
    "        \n",
    "os.makedirs(result_dir, exist_ok=False)\n",
    "shutil.copytree(\"lib\", os.path.join(result_dir, \"lib\"))\n",
    "shutil.copyfile(f\"notebooks/{FILE_NAME}.ipynb\", os.path.join(result_dir, f\"{FILE_NAME}.ipynb\"))\n",
    "preds.to_csv(os.path.join(result_dir, f\"submission.csv\"), index=True, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shap.TreeExplainer(best_model).shap_values(best_xval)\n",
    "shap.summary_plot(shap_values, best_xval, plot_type=\"bar\", show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install plyer\n",
    "from plyer import notification\n",
    "\n",
    "notification.notify(\n",
    "    title=\"From Python\",\n",
    "    message=\"Executed Successfully\",\n",
    "    app_name='Python',\n",
    "    app_icon=os.path.join(BASE_PATH,'lib/notification.ico'),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LB: 0.4969328"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
